{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f0da9c",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39238fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "dataset = pd.read_csv(\"C:/Users/daxab/py projects/ml_projects/datasets/healthcare-dataset-stroke-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740ecfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for Missing Values\n",
    "\n",
    "missValues = dataset.isnull().sum()\n",
    "print(\"Missing Values:\", missValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6a275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any null values\n",
    "dataset.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d14d97",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bf384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_zero_invalid = ['age', 'hypertension', 'heart_disease', 'ever_married', 'work_type' , 'Residence_type', 'avg_glucose_level', 'bmi', 'smoking_status']\n",
    "\n",
    "zero_rows = dataset[(dataset[cols_with_zero_invalid] == 0).any(axis=1)]\n",
    "print(zero_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((dataset[cols_with_zero_invalid] == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52958ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "categorical_cols = ['hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "# Handle numeric columns - replace 0 with NaN and impute with median\n",
    "dataset[numeric_cols] = dataset[numeric_cols].replace(0, np.nan)\n",
    "numeric_imputer = SimpleImputer(strategy=\"median\")\n",
    "dataset[numeric_cols] = numeric_imputer.fit_transform(dataset[numeric_cols])\n",
    "\n",
    "# Handle categorical columns - impute missing values with mode (most frequent)\n",
    "categorical_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "dataset[categorical_cols] = categorical_imputer.fit_transform(dataset[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10422794",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check data types and unique values before encoding\n",
    "print(\"Data types:\")\n",
    "print(dataset.dtypes)\n",
    "print(\"\\nUnique values in each column:\")\n",
    "for col in dataset.columns:\n",
    "    print(f\"{col}: {dataset[col].unique()}\")\n",
    "\n",
    "# Encode ALL categorical variables\n",
    "categorical_cols_all = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols_all:\n",
    "    if col in dataset.columns and dataset[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        dataset[col] = le.fit_transform(dataset[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded {col}: {le.classes_}\")\n",
    "\n",
    "# Correlation Matrix Heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = dataset.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Matrix Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prepare features and target\n",
    "X = dataset.drop('stroke', axis=1)  # Features\n",
    "y = dataset['stroke']  # Target variable\n",
    "\n",
    "# Check if there are still any object columns\n",
    "print(\"\\nData types after encoding:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_pred_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature importance heatmap\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': abs(log_reg.coef_[0])\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(feature_importance.set_index('feature')[['importance']], \n",
    "            annot=True, cmap='viridis', fmt='.3f')\n",
    "plt.title('Feature Importance Heatmap (Logistic Regression Coefficients)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3453552",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the same preprocessed data from logistic regression\n",
    "# X_train_scaled, X_test_scaled, y_train, y_test are already available\n",
    "\n",
    "# Check class distribution\n",
    "print(\"Class distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Create SVM model with class balancing\n",
    "svm_model = SVC(kernel='rbf', random_state=42, probability=True, class_weight='balanced')\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "y_pred_proba_svm = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate the SVM model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {accuracy_svm:.4f}\")\n",
    "print(\"\\nSVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm, zero_division=0))\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV - reduced grid for faster execution\n",
    "print(\"\\nPerforming hyperparameter tuning...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(random_state=42, probability=True), \n",
    "                          param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train best model\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate best model\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"\\nBest SVM Accuracy: {accuracy_best:.4f}\")\n",
    "print(\"\\nBest SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best, zero_division=0))\n",
    "\n",
    "# Compare models\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'SVM (default)', 'SVM (tuned)'],\n",
    "    'Accuracy': [accuracy, accuracy_svm, accuracy_best]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=comparison, x='Model', y='Accuracy')\n",
    "plt.title('Model Comparison - Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(comparison['Accuracy']):\n",
    "    plt.text(i, v + 0.01, f'{v:.4f}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_one",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
